{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cosine\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "##change working directory\n",
    "os.chdir('/home/jcai/geometry_of_law/data_and_dictionary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "##loading average dictionaries\n",
    "Y_average_dict = pk.load(open( \"Y_average_dict.p\", \"rb\" ))\n",
    "CBY_average_dict = pk.load(open( \"CBY_average_dict.p\", \"rb\" ))\n",
    "JY_average_dict = pk.load(open( \"JY_average_dict.p\", \"rb\" ))\n",
    "YB_average_dict = pk.load(open( \"YB_average_dict.p\", \"rb\" ))\n",
    "CB_average_dict = pk.load(open( \"CB_average_dict.p\", \"rb\" ))\n",
    "CY_average_dict = pk.load(open( \"CY_average_dict.p\", \"rb\" ))\n",
    "JD_average_dict = pk.load(open( \"JD_average_dict.p\", \"rb\" ))\n",
    "CD_average_dict = pk.load(open( \"CD_average_dict.p\", \"rb\" ))\n",
    "C_average_dict = pk.load(open( \"C_average_dict.p\", \"rb\" ))\n",
    "judge_average_dict = pk.load(open( \"judge_average_dict.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "##loading attribute dictionaries\n",
    "Y_dict = pk.load(open( \"Y_dict.p\", \"rb\" ))\n",
    "CBY_dict = pk.load(open( \"CBY_dict.p\", \"rb\" ))\n",
    "JY_dict = pk.load(open( \"JY_dict.p\", \"rb\" ))\n",
    "YB_dict = pk.load(open( \"YB_dict.p\", \"rb\" ))\n",
    "CB_dict = pk.load(open( \"CB_dict.p\", \"rb\" ))\n",
    "CY_dict = pk.load(open( \"CY_dict.p\", \"rb\" ))\n",
    "JD_dict = pk.load(open( \"JD_dict.p\", \"rb\" ))\n",
    "CD_dict = pk.load(open( \"CD_dict.p\", \"rb\" ))\n",
    "C_dict = pk.load(open( \"C_dict.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "##importing master_dataframe\n",
    "master_dataframe = pd.read_csv(\"/home/jcai/geometry_of_law/Encyclopedia Entry/master_dataframe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec.load('/home/jcai/geometry_of_law/doc2vec_v50k_d200_shuffled_opinion/ALL_opinion.d2v')\n",
    "set_of_doc_names = set(model.docvecs.doctags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dataframe = master_dataframe[master_dataframe['docname'].isin(set_of_doc_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_list_of_docname(column, value):\n",
    "    '''returns the list of docname of the vectors whose column is value'''\n",
    "    list_of_docname = list(master_dataframe.loc[master_dataframe[column]==value]['docname'])\n",
    "    return list_of_docname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_list_of_docname_2_values(column_1, value_1, column_2, value_2):\n",
    "    '''returns two list of docnames according to 2 values'''\n",
    "    list_1 = return_list_of_docname(column_1, value_1)\n",
    "    list_2 = return_list_of_docname(column_2, value_2)\n",
    "    list_of_docname = list(set(list_1) & set(list_2))\n",
    "    return list_of_docname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_average_vector(list_of_docname):\n",
    "    '''returns the average vector for the given list of docname'''\n",
    "    list_of_vectors = [model[x] for x in list_of_docname]\n",
    "    mean = np.mean(list_of_vectors, axis=0)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "##return the least similar vector\n",
    "##depends on importing the d2v model as \"model\"\n",
    "## and the previously defined functions\n",
    "def return_vector_dissimilar_to_average(judge, attr_1, number_of_return, ascending_or_not):\n",
    "    '''returns those among the judge's for the given list of docname'''\n",
    "    list_of_docname = return_list_of_docname_2_values(\"judge_name\",judge,\"big-issue\",attr_1)\n",
    "    average_vec = return_average_vector(list_of_docname)\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df[\"docname\"] = list_of_docname\n",
    "    temp_df[\"similarity\"] = [1 - cosine(model[x],average_vec) for x in list_of_docname]\n",
    "    \n",
    "    temp_df = temp_df.sort_values(\"similarity\", ascending = ascending_or_not)\n",
    "    return temp_df[:number_of_return]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docname</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>X12N0L2003_contentMajOp_SCHALL.txt</td>\n",
       "      <td>0.605013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>X1BN634003_contentMajOp_SCHALL.txt</td>\n",
       "      <td>0.595868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>X361C11_contentMajOp_Schall.txt</td>\n",
       "      <td>0.595516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>X12LP0I003_contentMajOp_SCHALL.txt</td>\n",
       "      <td>0.572147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>XI5530N_contentMajOp_SCHALL.txt</td>\n",
       "      <td>0.571097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               docname  similarity\n",
       "69  X12N0L2003_contentMajOp_SCHALL.txt    0.605013\n",
       "35  X1BN634003_contentMajOp_SCHALL.txt    0.595868\n",
       "22     X361C11_contentMajOp_Schall.txt    0.595516\n",
       "43  X12LP0I003_contentMajOp_SCHALL.txt    0.572147\n",
       "61     XI5530N_contentMajOp_SCHALL.txt    0.571097"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to test \n",
    "return_vector_dissimilar_to_average('SCHALL, ALVIN ANTHONY','4',5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "docname_vector_dict = pk.load(open( \"docname_vector_dict.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_vec_demeaned_topic_year = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_both = list(set(docname_vector_dict.keys()).intersection(set(master_dataframe[\"docname\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## here we calculate for each opinion:\n",
    "## its difference the average opinion in its year and topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in in_both:\n",
    "    opinion_vec_demeaned_topic_year[key] = docname_vector_dict[key] - YB_average_dict[YB_dict[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk.dump(opinion_vec_demeaned_topic_year, open( \"opinion_vec_demeaned_topic_year.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## here we calculate for each judge:\n",
    "## the difference between his/her average opinion in its year and topic and the average opinion in its year and topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_topic_year_vec_demeaned_topic_year = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_topic_year_vec_demeaned_topic_year_more_than_one = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_judges = list(master_dataframe['judge_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_judge_topic_year = master_dataframe.groupby([\"judge_name\",'year-big-issue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in grouped_by_judge_topic_year:\n",
    "    judge_topic_year_vec_demeaned_topic_year[name[0]+'-'+name[1]] = return_average_vector(group[\"docname\"].values) - YB_average_dict[name[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculating_opinion_YB_judge_YB_dis(docname):\n",
    "    try:\n",
    "        judge_YB = JY_dict[docname]+'-'+YB_dict[docname].split(\"-\")[1]\n",
    "        return cosine(judge_topic_year_vec_demeaned_topic_year[judge_YB],opinion_vec_demeaned_topic_year[docname])\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating_opinion_YB_judge_YB_dis_distance('X3FE6A_contentMajOp_WILLIAMS.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_YB_judge_YB_dis = pd.DataFrame()\n",
    "opinion_YB_judge_YB_dis[\"docname\"] = opinion_vec_demeaned_topic_year.keys()\n",
    "opinion_YB_judge_YB_dis[\"dis\"] = [calculating_opinion_YB_judge_YB_dis(x) for x in opinion_vec_demeaned_topic_year.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292747, 2)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opinion_YB_judge_YB_dis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_YB_judge_YB_dis = opinion_YB_judge_YB_dis.merge(master_dataframe, on = \"docname\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_YB_judge_YB_dis = opinion_YB_judge_YB_dis[opinion_YB_judge_YB_dis.dis.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_YB_judge_YB_dis[\"caseid\"] = [x.split(\"_\")[0] for x in opinion_YB_judge_YB_dis['docname']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_YB_judge_YB_dis.to_csv('/home/jcai/geometry_of_law/data_and_dictionary/opinion_YB_judge_YB_dis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculating_opinion_judge_YB_dis(docname):\n",
    "    try:\n",
    "        judge_YB = JY_dict[docname]+'-'+YB_dict[docname].split(\"-\")[1]\n",
    "        return cosine(judge_topic_year_vec_demeaned_topic_year[judge_YB],opinion_vec_demeaned_topic_year[docname])\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in judge_topic_year_vec_demeaned_judge_topic_year:\n",
    "    judge_topic_year_vec_demeaned_judge_topic_year[name[0]+'-'+name[1]] = return_average_vector(group[\"docname\"].values) - YB_average_dict[name[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# here we calculate distance between average opinion in its year and topic and this opinion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculating_opinion_YB_dis(docname):\n",
    "    try:\n",
    "        return cosine(YB_average_dict[YB_dict[docname]],docname_vector_dict[docname])\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_YB_dis = pd.DataFrame()\n",
    "opinion_YB_dis[\"docname\"] = opinion_vec_demeaned_topic_year.keys()\n",
    "opinion_YB_dis[\"dis\"] = [calculating_opinion_YB_dis(x) for x in opinion_vec_demeaned_topic_year.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_YB_dis = opinion_YB_dis.merge(master_dataframe, on = \"docname\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_YB_dis[\"caseid\"] = [x.split(\"_\")[0] for x in opinion_YB_dis['docname']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_YB_dis.to_csv('/home/jcai/geometry_of_law/data_and_dictionary/opinion_YB_dis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_data = pd.read_csv('/home/jcai/geometry_of_law/data_and_dictionary/circuit_case_sc_decision_map_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = opinion_YB_judge_YB_dis.copy().merge(outcome_data, how = \"left\",on = \"caseid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292733, 34)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as sm\n",
    "import statsmodels.stats.sandwich_covariance as sw\n",
    "import numpy as np\n",
    "import statsmodels as statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_affirmed = merged.copy()\n",
    "merged_affirmed = merged_affirmed[merged_affirmed.if_affirmed.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_all_affirmed = merged_all.copy()\n",
    "merged_all_affirmed = merged_all_affirmed[merged_all_affirmed.if_affirmed.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_court_affirmed_ols = sm.ols(formula='if_affirmed ~ dis', data=merged_affirmed).fit(cov_type='cluster',\n",
    "                                                        cov_kwds={'groups': merged_affirmed['Circuit']},\n",
    "                                                        use_t=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>if_affirmed</td>   <th>  R-squared:         </th>  <td>   0.001</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.001</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   5.756</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 24 Jan 2019</td> <th>  Prob (F-statistic):</th>   <td>0.0336</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>02:28:51</td>     <th>  Log-Likelihood:    </th> <td>-1.7970e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>264324</td>      <th>  AIC:               </th>  <td>3.594e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>264322</td>      <th>  BIC:               </th>  <td>3.594e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>       <td>cluster</td>     <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.6814</td> <td>    0.020</td> <td>   33.458</td> <td> 0.000</td> <td>    0.637</td> <td>    0.726</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dis</th>       <td>   -0.0750</td> <td>    0.031</td> <td>   -2.399</td> <td> 0.034</td> <td>   -0.143</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14313.011</td> <th>  Durbin-Watson:     </th> <td>   1.998</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>45548.812</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.617</td>   <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 1.384</td>   <th>  Cond. No.          </th> <td>    7.29</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors are robust tocluster correlation (cluster)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            if_affirmed   R-squared:                       0.001\n",
       "Model:                            OLS   Adj. R-squared:                  0.001\n",
       "Method:                 Least Squares   F-statistic:                     5.756\n",
       "Date:                Thu, 24 Jan 2019   Prob (F-statistic):             0.0336\n",
       "Time:                        02:28:51   Log-Likelihood:            -1.7970e+05\n",
       "No. Observations:              264324   AIC:                         3.594e+05\n",
       "Df Residuals:                  264322   BIC:                         3.594e+05\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:              cluster                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.6814      0.020     33.458      0.000       0.637       0.726\n",
       "dis           -0.0750      0.031     -2.399      0.034      -0.143      -0.007\n",
       "==============================================================================\n",
       "Omnibus:                    14313.011   Durbin-Watson:                   1.998\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            45548.812\n",
       "Skew:                          -0.617   Prob(JB):                         0.00\n",
       "Kurtosis:                       1.384   Cond. No.                         7.29\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors are robust tocluster correlation (cluster)\n",
       "\"\"\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_court_affirmed_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_Dissenting1 = merged.copy()\n",
    "merged_Dissenting1 = merged_Dissenting1[merged_Dissenting1.Dissenting1.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_all_Dissenting1 = merged_all.copy()\n",
    "merged_all_Dissenting1 = merged_all_Dissenting1[merged_all_Dissenting1.Dissenting1.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_court_Dissenting1_ols = sm.ols(formula='Dissenting1 ~ dis', data=merged_Dissenting1).fit(cov_type='cluster',\n",
    "                                                        cov_kwds={'groups': merged_Dissenting1['Circuit']},\n",
    "                                                        use_t=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Dissenting1</td>   <th>  R-squared:         </th>  <td>   0.002</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.002</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   40.76</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 24 Jan 2019</td> <th>  Prob (F-statistic):</th>  <td>3.48e-05</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>02:28:52</td>     <th>  Log-Likelihood:    </th> <td>-2.5346e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>264019</td>      <th>  AIC:               </th>  <td>5.069e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>264017</td>      <th>  BIC:               </th>  <td>5.069e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>       <td>cluster</td>     <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.1113</td> <td>    0.010</td> <td>   10.887</td> <td> 0.000</td> <td>    0.089</td> <td>    0.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dis</th>       <td>    0.1614</td> <td>    0.025</td> <td>    6.385</td> <td> 0.000</td> <td>    0.106</td> <td>    0.216</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>187678.017</td> <th>  Durbin-Watson:     </th>  <td>   2.004</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>2003318.785</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 3.532</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td>14.499</td>   <th>  Cond. No.          </th>  <td>    7.29</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors are robust tocluster correlation (cluster)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            Dissenting1   R-squared:                       0.002\n",
       "Model:                            OLS   Adj. R-squared:                  0.002\n",
       "Method:                 Least Squares   F-statistic:                     40.76\n",
       "Date:                Thu, 24 Jan 2019   Prob (F-statistic):           3.48e-05\n",
       "Time:                        02:28:52   Log-Likelihood:            -2.5346e+05\n",
       "No. Observations:              264019   AIC:                         5.069e+05\n",
       "Df Residuals:                  264017   BIC:                         5.069e+05\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:              cluster                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.1113      0.010     10.887      0.000       0.089       0.134\n",
       "dis            0.1614      0.025      6.385      0.000       0.106       0.216\n",
       "==============================================================================\n",
       "Omnibus:                   187678.017   Durbin-Watson:                   2.004\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          2003318.785\n",
       "Skew:                           3.532   Prob(JB):                         0.00\n",
       "Kurtosis:                      14.499   Cond. No.                         7.29\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors are robust tocluster correlation (cluster)\n",
       "\"\"\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_court_Dissenting1_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.discrete.discrete_model import Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.649245\n",
      "         Iterations 4\n"
     ]
    }
   ],
   "source": [
    "cluster_court_affirmed_logit_all = Logit.from_formula(formula='if_affirmed ~ dis', data=merged_all_affirmed).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>if_affirmed</td>   <th>  No. Observations:  </th>   <td>288749</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>288747</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     1</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Thu, 24 Jan 2019</td> <th>  Pseudo R-squ.:     </th>  <td>0.0003878</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>02:47:55</td>     <th>  Log-Likelihood:    </th> <td>-1.8747e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-1.8754e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td>1.713e-33</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.7103</td> <td>    0.010</td> <td>   73.812</td> <td> 0.000</td> <td>    0.691</td> <td>    0.729</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dis</th>       <td>   -0.2126</td> <td>    0.018</td> <td>  -12.076</td> <td> 0.000</td> <td>   -0.247</td> <td>   -0.178</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:            if_affirmed   No. Observations:               288749\n",
       "Model:                          Logit   Df Residuals:                   288747\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Thu, 24 Jan 2019   Pseudo R-squ.:               0.0003878\n",
       "Time:                        02:47:55   Log-Likelihood:            -1.8747e+05\n",
       "converged:                       True   LL-Null:                   -1.8754e+05\n",
       "                                        LLR p-value:                 1.713e-33\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.7103      0.010     73.812      0.000       0.691       0.729\n",
       "dis           -0.2126      0.018    -12.076      0.000      -0.247      -0.178\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_court_affirmed_logit_all.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
