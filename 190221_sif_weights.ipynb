{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "import pandas\n",
    "import numpy\n",
    "import pickle\n",
    "import gensim\n",
    "import operator\n",
    "import re\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from typing import Iterable\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from nltk import tokenize, casual_tokenize\n",
    "import nltk \n",
    "from zipfile import ZipFile\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktTrainer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('/home/jcai/geometry_of_law/word2vec_v20480_d256_shuffled_opinion/cc.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, vocab_obj in model.wv.vocab.items():\n",
    "    word_count_dict[word] = vocab_obj.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sif_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, count in word_count_dict.items():\n",
    "    sif_dict[word] = .001/(.001+count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk.dump(sif_dict, open( \"/home/jcai/geometry_of_law/word2vec_v20480_d256_shuffled_opinion/cc_sif_dict.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jcai/geometry_of_law is wd\n"
     ]
    }
   ],
   "source": [
    "# defines vocabulary size and vector dimension\n",
    "voc_size = 20480\n",
    "vec_dim  = 256\n",
    "model_name = 'cc'\n",
    "directory_name = 'word2vec_v20480_d256_shuffled_opinion'\n",
    "\n",
    "\n",
    "# configues loggin\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO, filename=directory_name+'/'+model_name+'.log')\n",
    "console = logging.StreamHandler()\n",
    "console.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s : %(levelname)s : %(message)s')\n",
    "console.setFormatter(formatter)\n",
    "logging.getLogger('').addHandler(console)\n",
    "\n",
    "# sets working directory\n",
    "wd = '/home/jcai/geometry_of_law'\n",
    "os.chdir(wd)\n",
    "print(wd + ' is wd')\n",
    "\n",
    "#read zipfiles\n",
    "zfile_cc = ZipFile('/data/Data/Circuit_Courts/circuit-cases/sentences.zip', allowZip64 = True)\n",
    "items_cc = [(\"cc\", x) for x in zfile_cc.namelist()]\n",
    "items_cc = [x for x in items_cc if '.txt' in x[1]]\n",
    "items_cc = [x for x in items_cc if int(x[1].split(\"/\")[1].split(\"_\")[1]) in range(1970,2006)]\n",
    "\n",
    "shuffle(items_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stopword\n",
    "stopwords_year = [str(x) for x in list(range(1970,2005))]\n",
    "\n",
    "#get judgenames\n",
    "judge_bio = pd.read_stata(\"/data/Data/Judge-Bios/judgebios/JudgesBioReshaped_TOUSE.dta\")\n",
    "\n",
    "stopwords_judge_name = list(judge_bio['judgefirstname']) + list(judge_bio['judgelastname'])\n",
    "\n",
    "#defines a tokenizer that does not save punctuation and convert everything to lower case\n",
    "#also removes stopwords\n",
    "stop = stopwords.words('english') + stopwords_year + stopwords_judge_name\n",
    "stop = [x.lower() for x in stop]\n",
    "stop = set(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_no_punct_all_lower(txt):\n",
    "    txt_tokenize = casual_tokenize(txt,preserve_case=False,strip_handles=True)\n",
    "    txt_tokenize = [word for word in txt_tokenize if re.sub(r\"\\-\", \"\", word).isalpha()]\n",
    "    txt_tokenize = [word for word in txt_tokenize if word not in stop]\n",
    "    return txt_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_set = set(model.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines iterator that splits by lines\n",
    "def document_lines_vec(docnames):\n",
    "    fname = docnames.split('/')[-1]\n",
    "    txt = zfile_cc.open(docnames,\"r\").read()\n",
    "    txt = txt.decode(\"utf-8\")\n",
    "    tokens = tokenize_no_punct_all_lower(txt)\n",
    "    tokens_tagged = nltk.pos_tag(tokens,tagset='universal')\n",
    "    tokens = [i[0] for i in tokens_tagged if i[1] in [\"VERB\",\"NOUN\",\"ADJ\",\"ADV\"]]\n",
    "    tokens = [t for t in tokens if t in vocab_set]\n",
    "    sif_vec = np.mean([sif_dict[t]*model.wv[t] for t in tokens],axis=0)\n",
    "    return sif_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sif_vec_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in items_cc:\n",
    "    sif_vec_dict[item[1].split('/')[-1]] = document_lines_vec(item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk.dump(sif_vec_dict, \n",
    "        open( \"/home/jcai/geometry_of_law/word2vec_v20480_d256_shuffled_opinion/cc_sif_vec_dict.p\", \"wb\" ))\n",
    "print(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
