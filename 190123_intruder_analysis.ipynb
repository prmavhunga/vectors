{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from random import sample\n",
    "from scipy.spatial.distance import cosine\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import dec2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec.load('/home/jcai/geometry_of_law/doc2vec_v50k_d200_shuffled_opinion/ALL_opinion.d2v')\n",
    "set_of_doc_names = set(model.docvecs.doctags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import master dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dataframe = pd.read_csv(\"/home/jcai/geometry_of_law/Encyclopedia Entry/master_dataframe.csv\")\n",
    "master_dataframe = master_dataframe[master_dataframe['docname'].isin(set_of_doc_names)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_average_vector(list_of_docname):\n",
    "    '''returns the average vector for the given list of docname'''\n",
    "    list_of_vectors = [model[x] for x in list_of_docname]\n",
    "    mean = np.mean(list_of_vectors, axis=0)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define the intruder_sample function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['docname', 'judge_name', 'party', 'year', 'circuit', 'circuit-year',\n",
       "       'big-issue', 'detailed-issue', 'circuit-big-issue', 'year-big-issue',\n",
       "       'circuit-big-issue-year', 'judge-year', 'decade', 'judge-decade',\n",
       "       'court-decade'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_with_over_10_documents = []\n",
    "for judge,count in master_dataframe.groupby(\"judge_name\").count()['docname'].reset_index(name=\"count\").itertuples(index=False):\n",
    "    if count > 10:\n",
    "        judge_with_over_10_documents.append(judge)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intruder_sample(size, opinion_restriction = []):\n",
    "    \n",
    "    if len(opinion_restriction) == 0:\n",
    "        judge = sample(judge_with_over_10_documents,1)[0]\n",
    "        judge_list = sample(list(master_dataframe[master_dataframe['judge_name'] == judge]['docname'].values),size)\n",
    "        intruder_opinion = sample(list(master_dataframe['docname'].values),1)\n",
    "        \n",
    "        judge_avg_vec = return_average_vector(judge_list)\n",
    "        intruder_vec = model[intruder_opinion[0]]\n",
    "        \n",
    "        judge_sim_list = [1 - cosine(judge_avg_vec,model[i]) for i in judge_list]\n",
    "        intruder_sim = 1 - cosine(judge_avg_vec,intruder_vec)\n",
    "        \n",
    "        if intruder_sim > min(judge_sim_list):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "    else:\n",
    "        try:\n",
    "            group_key = []\n",
    "            \n",
    "            for item in opinion_restriction:\n",
    "                key = sample(list(master_dataframe[master_dataframe[item].notna()][item].unique()),1)[0]\n",
    "                group_key.append(key)\n",
    "                \n",
    "            if len(group_key) == 1:\n",
    "                restricted_group = master_dataframe.groupby(opinion_restriction).get_group(*group_key)\n",
    "            else:\n",
    "                restricted_group = master_dataframe.groupby(opinion_restriction).get_group(tuple(group_key))\n",
    "            \n",
    "            judge_over_10_documents = []\n",
    "            for judge, count in restricted_group.groupby(\"judge_name\").count()['docname'].reset_index(name=\"count\").itertuples(index=False):\n",
    "                if count > 10:\n",
    "                    judge_over_10_documents.append(judge)\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "            judge = sample(judge_over_10_documents,1)[0]\n",
    "            judge_list = sample(list(restricted_group[restricted_group['judge_name'] == judge]['docname'].values),size)\n",
    "            intruder_opinion = sample(list(restricted_group[restricted_group['judge_name'] != judge]['docname'].values),1)\n",
    "            \n",
    "            judge_avg_vec = return_average_vector(judge_list)\n",
    "            intruder_vec = model[intruder_opinion[0]]\n",
    "            \n",
    "            judge_sim_list = [1 - cosine(judge_avg_vec,model[i]) for i in judge_list]\n",
    "            intruder_sim = 1 - cosine(judge_avg_vec,intruder_vec)\n",
    "            \n",
    "            if intruder_sim > min(judge_sim_list):\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "        \n",
    "        except:\n",
    "            return intruder_sample(size, opinion_restriction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# intruder analysis: randomly sample a judge and an opinion from another judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [sum([intruder_sample(9)/100 for x in range(100)]) for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precent detected is  0.9780000000000006  stdev is  0.016613247725836163\n"
     ]
    }
   ],
   "source": [
    "print('The precent detected is ', np.mean(results), ' stdev is ' , np.std(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# intruder analysis: randomly sample a judge and an opinion from another judge | the opinions are from the same circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [sum([intruder_sample(9,['circuit']) for x in range(100)])/100 for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precent detected is  0.924  stdev is  0.022449944320643633\n"
     ]
    }
   ],
   "source": [
    "print('The precent detected is ', np.mean(results), ' stdev is ' , np.std(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# intruder analysis: randomly sample a judge and an opinion from another judge | the opinions are from the same issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [sum([intruder_sample(9,['big-issue']) for x in range(10)])/10 for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precent detected is  0.8800000000000001  stdev is  0.08717797887081348\n"
     ]
    }
   ],
   "source": [
    "print('The precent detected is ', np.mean(results), ' stdev is ' , np.std(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# intruder analysis: randomly sample a judge and an opinion from another judge | the opinions are from the same year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [sum([intruder_sample(9,['year']) for x in range(10)])/10 for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precent detected is  0.8899999999999999  stdev is  0.06999999999999999\n"
     ]
    }
   ],
   "source": [
    "print('The precent detected is ', np.mean(results), ' stdev is ' , np.std(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# intruder analysis: randomly sample a judge and an opinion from another judge | the opinions are from the same circuit and big issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [sum([intruder_sample(9,['circuit','big-issue']) for x in range(10)])/10 for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precent detected is  0.9  stdev is  0.07745966692414835\n"
     ]
    }
   ],
   "source": [
    "print('The precent detected is ', np.mean(results), ' stdev is ' , np.std(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# intruder analysis: randomly sample a judge and an opinion from another judge | the opinions are from the same year and big issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [sum([intruder_sample(9,['year','big-issue']) for x in range(10)])/10 for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precent detected is  0.8900000000000002  stdev is  0.08306623862918074\n"
     ]
    }
   ],
   "source": [
    "print('The precent detected is ', np.mean(results), ' stdev is ' , np.std(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# intruder analysis: randomly sample a judge and an opinion from another judge | the opinions are from the same year, big issue, circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [sum([intruder_sample(9,['year','big-issue','circuit']) for x in range(10)])/10 for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precent detected is  0.78  stdev is  0.0871779788708135\n"
     ]
    }
   ],
   "source": [
    "print('The precent detected is ', np.mean(results), ' stdev is ' , np.std(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
